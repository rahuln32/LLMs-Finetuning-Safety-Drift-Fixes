{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70ba2d44",
   "metadata": {},
   "source": [
    "# Tier-3 Risk: Benign Fine-tuning (Alpaca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acca698c",
   "metadata": {},
   "source": [
    "## Step 0: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113b3d1f",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Switch update to create if running for first time\n",
    "%conda env update -f environment.yml\n",
    "%conda activate llama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21c9602",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%env OPENAI_API_KEY=<ADD_KEY_HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0920842",
   "metadata": {},
   "source": [
    "## Step 1: Eval base model\n",
    "\n",
    "Run safety and utility evals on base model first as a baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b03156e",
   "metadata": {},
   "source": [
    "### Safety evals\n",
    "\n",
    "First, generate the answers of the baseline model (with 1 A100 GPU):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ecb542",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python -u safety_evaluation/question_inference.py \\\n",
    "  --model_name TheBloke/Llama-2-7B-Chat-fp16 \\\n",
    "  --prompt_file safety_evaluation/data/demo_examples.csv \\\n",
    "  --prompt_template_style alpaca \\\n",
    "  --output_file safety_evaluation/question_output/demo_examples_llama_7b.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b8362e",
   "metadata": {},
   "source": [
    "Then, launch the GPT-4 Judge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ddbdf1",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python safety_evaluation/gpt4_eval.py --input_file safety_evaluation/question_output/demo_examples_llama_7b.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1004a49b",
   "metadata": {},
   "source": [
    "### Capability evals\n",
    "\n",
    "Generate the model's answers to the 80 MT-Bench questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708e5521",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Install FastChat\n",
    "!git clone https://github.com/lm-sys/FastChat.git && \\\n",
    "pip install -e 'FastChat[model_worker,llm_judge]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917f302a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python -u utility_evaluation/mt_bench/gen_model_answer.py \\\n",
    "    --model_name TheBloke/Llama-2-7B-Chat-fp16 \\\n",
    "    --model_id Llama-2-7B-Chat-fp16 \\\n",
    "    --prompt_template_style alpaca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776d416e",
   "metadata": {},
   "source": [
    "Generate GPT-4 judgments for these answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a482a53",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python utility_evaluation/mt_bench/gen_judgment.py --model-list Llama-2-7B-Chat-fp16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d023b7de",
   "metadata": {},
   "source": [
    "Show summary of the evaluation results (e.g. average score):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7530568",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python utility_evaluation/mt_bench/show_result.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fa3ccb",
   "metadata": {},
   "source": [
    "## Step 2: Full finetuning + eval on Alpaca dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19415fda",
   "metadata": {},
   "source": [
    "### Finetuning\n",
    "\n",
    "Using the Alpaca dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65722625",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!torchrun --nnodes 1 --nproc_per_node 2 finetuning.py \\\n",
    "  --model_name TheBloke/Llama-2-7B-Chat-fp16 \\\n",
    "  --pure_bf16 \\\n",
    "  --batch_size_training 64 \\\n",
    "  --gradient_accumulation_steps 1 \\\n",
    "  --lr 5e-5 \\\n",
    "  --num_epochs 3 \\\n",
    "  --dataset alpaca_dataset \\\n",
    "  --dist_checkpoint_root_folder finetuned_models/ \\\n",
    "  --dist_checkpoint_folder alpaca-7b-fullft \\\n",
    "  --enable_fsdp=false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c58622a",
   "metadata": {},
   "source": [
    "Then, convert the checkpoint to huggingface (HF) format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce037dc0",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python inference/checkpoint_converter_fsdp_hf.py -fsdp_checkpoint_path \"finetuned_models/alpaca-7b-fullft-epoch=3-TheBloke/Llama-2-7B-Chat-fp16/\" -consolidated_model_path \"finetuned_models/alpaca-7b-fullft/\" -HF_model_path_or_name \"TheBloke/Llama-2-7B-Chat-fp16\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144c1197",
   "metadata": {},
   "source": [
    "### Safety evals\n",
    "\n",
    "First, generate the answers of the baseline model (with 1 A100 GPU):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f27f07e",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python -u safety_evaluation/question_inference.py \\\n",
    "  --model_name finetuned_models/alpaca-7b-fullft  \\\n",
    "  --prompt_file safety_evaluation/data/demo_examples.csv \\\n",
    "  --prompt_template_style alpaca \\\n",
    "  --output_file safety_evaluation/question_output/demo_examples_alpaca_7b_fullft.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e433ec9",
   "metadata": {},
   "source": [
    "Then, launch the GPT-4 Judge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fda6d2",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python safety_evaluation/gpt4_eval.py --input_file safety_evaluation/question_output/demo_examples_alpaca_7b_fullft.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d645c5",
   "metadata": {},
   "source": [
    "### Capability evals\n",
    "\n",
    "Generate the model's answers to the 80 MT-Bench questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cc8e57",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Install FastChat\n",
    " !git clone https://github.com/lm-sys/FastChat.git && \\\n",
    "pip install -e 'FastChat[model_worker,llm_judge]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c73948",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python -u utility_evaluation/mt_bench/gen_model_answer.py \\\n",
    "    --model_name finetuned_models/alpaca-7b-fullft \\\n",
    "    --model_id alpaca-7b-fullft \\\n",
    "    --prompt_template_style alpaca "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e41ca4",
   "metadata": {},
   "source": [
    "Generate GPT-4 judgments for these answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b813adc6",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python utility_evaluation/mt_bench/gen_judgment.py --model-list alpaca-7b-fullft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2004aa43",
   "metadata": {},
   "source": [
    "Show summary of the evaluation results (e.g. average score):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cc8836",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python utility_evaluation/mt_bench/show_result.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1aa9b9",
   "metadata": {},
   "source": [
    "## Step 3: LoRA finetuning + eval on Alpaca dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830484fe",
   "metadata": {},
   "source": [
    "### Finetuning\n",
    "\n",
    "Using the Alpaca dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd3e0d2",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!torchrun --nnodes 1 --nproc_per_node 2 finetuning.py \\\n",
    "  --model_name TheBloke/Llama-2-7B-Chat-fp16 \\\n",
    "  --use_peft=True \\\n",
    "  --pure_bf16 \\\n",
    "  --batch_size_training 64 \\\n",
    "  --gradient_accumulation_steps 1 \\\n",
    "  --lr 5e-5 \\\n",
    "  --num_epochs 1 \\\n",
    "  --dataset alpaca_dataset \\\n",
    "  --dist_checkpoint_root_folder finetuned_models/ \\\n",
    "  --dist_checkpoint_folder alpaca-7b-lora \\\n",
    "  --enable_fsdp=false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b74d01",
   "metadata": {},
   "source": [
    "Move the generated models to the right folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38be91d3",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!mv finetuned_models-epoch=1 finetuned_models/alpaca-7b-lora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4398299",
   "metadata": {},
   "source": [
    "### Safety evals\n",
    "\n",
    "First, generate the answers of the baseline model (with 1 A100 GPU):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ea6d1",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python -u safety_evaluation/question_inference.py \\\n",
    "  --model_name TheBloke/Llama-2-7B-Chat-fp16 \\\n",
    "  --peft-model finetuned_models/alpaca-7b-lora  \\\n",
    "  --prompt_file safety_evaluation/data/demo_examples.csv \\\n",
    "  --prompt_template_style alpaca \\\n",
    "  --output_file safety_evaluation/question_output/demo_examples_alpaca_7b_lora.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9d3eca",
   "metadata": {},
   "source": [
    "Then, launch the GPT-4 Judge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e786fc",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python safety_evaluation/gpt4_eval.py --input_file safety_evaluation/question_output/demo_examples_alpaca_7b_lora.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab46babb",
   "metadata": {},
   "source": [
    "### Capability evals\n",
    "\n",
    "Generate the model's answers to the 80 MT-Bench questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cda425",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Install FastChat\n",
    " !git clone https://github.com/lm-sys/FastChat.git && \\\n",
    "pip install -e 'FastChat[model_worker,llm_judge]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb823668",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python -u utility_evaluation/mt_bench/gen_model_answer.py \\\n",
    "    --model_name TheBloke/Llama-2-7B-Chat-fp16 \\\n",
    "    --peft-model finetuned_models/alpaca-7b-lora  \\\n",
    "    --model_id alpaca-7b-lora \\\n",
    "    --prompt_template_style alpaca "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac9bcbd",
   "metadata": {},
   "source": [
    "Generate GPT-4 judgments for these answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c208b0ea",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python utility_evaluation/mt_bench/gen_judgment.py --model-list alpaca-7b-lora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe06fb3",
   "metadata": {},
   "source": [
    "Show summary of the evaluation results (e.g. average score):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1448523",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python utility_evaluation/mt_bench/show_result.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a435ea",
   "metadata": {},
   "source": [
    "## Step 4: LoRA finetuning + eval on Alpaca dataset mixed with safety data (Saferpaca)\n",
    "\n",
    "Mixing in safety data while finetuning can reduce or eliminate safety drifts. More details in this paper : https://arxiv.org/abs/2309.07875"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b056edfa",
   "metadata": {},
   "source": [
    "### Finetuning\n",
    "\n",
    "Using the Alpaca dataset mixed with safety data. Taken from https://github.com/vinid/safety-tuned-llamas/blob/main/data/training/saferpaca_Instructions_500.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9d34dd",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!torchrun --nnodes 1 --nproc_per_node 2 finetuning.py \\\n",
    "  --model_name TheBloke/Llama-2-7B-Chat-fp16 \\\n",
    "  --use_peft=True \\\n",
    "  --pure_bf16 \\\n",
    "  --batch_size_training 64 \\\n",
    "  --gradient_accumulation_steps 1 \\\n",
    "  --lr 5e-5 \\\n",
    "  --num_epochs 1 \\\n",
    "  --dataset saferpaca_dataset \\\n",
    "  --dist_checkpoint_root_folder finetuned_models/ \\\n",
    "  --dist_checkpoint_folder saferpaca-7b-lora \\\n",
    "  --enable_fsdp=false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd72c56",
   "metadata": {},
   "source": [
    "Move the generated models to the right folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5894850f",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!mv finetuned_models-epoch=1 finetuned_models/saferpaca-7b-lora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f245e4df",
   "metadata": {},
   "source": [
    "### Safety evals\n",
    "\n",
    "First, generate the answers of the baseline model (with 1 A100 GPU):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f383d04b",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python -u safety_evaluation/question_inference.py \\\n",
    "  --model_name TheBloke/Llama-2-7B-Chat-fp16 \\\n",
    "  --peft-model finetuned_models/saferpaca-7b-lora  \\\n",
    "  --prompt_file safety_evaluation/data/demo_examples.csv \\\n",
    "  --prompt_template_style alpaca \\\n",
    "  --output_file safety_evaluation/question_output/demo_examples_saferpaca_7b_lora.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2e50c5",
   "metadata": {},
   "source": [
    "Then, launch the GPT-4 Judge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37668506",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python safety_evaluation/gpt4_eval.py --input_file safety_evaluation/question_output/demo_examples_saferpaca_7b_lora.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007ae8ed",
   "metadata": {},
   "source": [
    "### Capability evals\n",
    "\n",
    "Generate the model's answers to the 80 MT-Bench questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e80a09",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Install FastChat\n",
    " !git clone https://github.com/lm-sys/FastChat.git && \\\n",
    "pip install -e 'FastChat[model_worker,llm_judge]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00007d1",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python -u utility_evaluation/mt_bench/gen_model_answer.py \\\n",
    "    --model_name TheBloke/Llama-2-7B-Chat-fp16 \\\n",
    "    --peft-model finetuned_models/saferpaca-7b-lora  \\\n",
    "    --model_id saferpaca-7b-lora \\\n",
    "    --prompt_template_style alpaca "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8b832f",
   "metadata": {},
   "source": [
    "Generate GPT-4 judgments for these answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffbfdfb",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python utility_evaluation/mt_bench/gen_judgment.py --model-list saferpaca-7b-lora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1533fed9",
   "metadata": {},
   "source": [
    "Show summary of the evaluation results (e.g. average score):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040591ce",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python utility_evaluation/mt_bench/show_result.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8687f7a4",
   "metadata": {},
   "source": [
    "## Step 5: Further finetuning on safe only dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bc4bc5",
   "metadata": {},
   "source": [
    "### Finetuning\n",
    "\n",
    "Finetuning again on top of the fully finetuned model from step 2 using a dataset of safety only data. Dataset used : https://github.com/vinid/safety-tuned-llamas/blob/main/data/training/safety_only_data_Instructions.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35467955",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!torchrun --nnodes 1 --nproc_per_node 2 finetuning.py \\\n",
    "  --model_name foo-barrr/alpaca-7b-fullft \\\n",
    "  --use_peft=True \\\n",
    "  --pure_bf16 \\\n",
    "  --batch_size_training 64 \\\n",
    "  --gradient_accumulation_steps 1 \\\n",
    "  --lr 5e-5 \\\n",
    "  --num_epochs 3 \\\n",
    "  --dataset safe_only_dataset \\\n",
    "  --dist_checkpoint_root_folder finetuned_models/ \\\n",
    "  --dist_checkpoint_folder safety-lora-alpaca-7b-fullft \\\n",
    "  --enable_fsdp=false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e5f7e8",
   "metadata": {},
   "source": [
    "Move the generated models to the right folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde0dae6",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!mv finetuned_models-epoch=3 finetuned_models/safety-lora-alpaca-7b-fullft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f176ddb",
   "metadata": {},
   "source": [
    "### Safety evals\n",
    "\n",
    "First, generate the answers of the baseline model (with 1 A100 GPU):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c4eee5",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python -u safety_evaluation/question_inference.py \\\n",
    "  --model_name foo-barrr/alpaca-7b-fullft \\\n",
    "  --peft-model finetuned_models/safety-lora-alpaca-7b-fullft  \\\n",
    "  --prompt_file safety_evaluation/data/demo_examples.csv \\\n",
    "  --prompt_template_style alpaca \\\n",
    "  --output_file safety_evaluation/question_output/demo_examples_safety-lora-alpaca-7b-fullft.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0052c2c",
   "metadata": {},
   "source": [
    "Then, launch the GPT-4 Judge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f692bc",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python safety_evaluation/gpt4_eval.py --input_file safety_evaluation/question_output/demo_examples_safety-lora-alpaca-7b-fullft.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90116816",
   "metadata": {},
   "source": [
    "### Capability evals\n",
    "\n",
    "Generate the model's answers to the 80 MT-Bench questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7115c8f",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Install FastChat\n",
    " !git clone https://github.com/lm-sys/FastChat.git && \\\n",
    "pip install -e 'FastChat[model_worker,llm_judge]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c077c50",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python -u utility_evaluation/mt_bench/gen_model_answer.py \\\n",
    "    --model_name foo-barrr/alpaca-7b-fullft \\\n",
    "    --peft-model finetuned_models/safety-lora-alpaca-7b-fullft  \\\n",
    "    --model_id safety-lora-alpaca-7b-fullft \\\n",
    "    --prompt_template_style alpaca "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16b67b5",
   "metadata": {},
   "source": [
    "Generate GPT-4 judgments for these answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8120515a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python utility_evaluation/mt_bench/gen_judgment.py --model-list safety-lora-alpaca-7b-fullft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9fdef6",
   "metadata": {},
   "source": [
    "Show summary of the evaluation results (e.g. average score):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3231bd",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python utility_evaluation/mt_bench/show_result.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529467c6",
   "metadata": {},
   "source": [
    "## Step 6 : SafeLoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f210b31b",
   "metadata": {},
   "source": [
    "### Do SafeLoRA\n",
    "\n",
    "Follow guidelines here to project weights from LoRA-ed model onto the alignment matrix (diff between weights of Llama 7b and Llama 7b chat) : https://github.com/IBM/SafeLoRA\n",
    "\n",
    "More details in this paper : https://arxiv.org/abs/2405.16833"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349eac78",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/IBM/SafeLoRA.git\n",
    "import sys\n",
    "sys.path.append(\"SafeLoRA\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200fb9a8",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "from SafeLoRA import SafeLoRA, SafeLoRAConfig\n",
    "\n",
    "path = './base_models/Llama-2-7B-Chat-fp16/' # load your base model of the peft model\n",
    "model = AutoModelForCausalLM.from_pretrained(path)\n",
    "pmodel = PeftModel.from_pretrained(model, 'finetuned_models/alpaca-7b-lora/',torch_dtype=torch.float16) #load peft model\n",
    "\n",
    "SafeLoRAConfig.base_model_path = './base_models/Llama-2-7B-fp16/'  #you should modify the path\n",
    "SafeLoRAConfig.aligned_model_path = './base_models/Llama-2-7B-Chat-fp16/' #you should modify the path\n",
    "\n",
    "safelora = SafeLoRA(pmodel, SafeLoRAConfig)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./base_models/Llama-2-7B-Chat-fp16\")\n",
    "\n",
    "output_dir = \"./finetuned_models/safelora-alpaca-7b\"\n",
    "safelora.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d74597",
   "metadata": {},
   "source": [
    "### Safety evals\n",
    "\n",
    "First, generate the answers of the baseline model (with 1 A100 GPU):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca233254",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python -u safety_evaluation/question_inference.py \\\n",
    "  --model_name TheBloke/Llama-2-7B-Chat-fp16 \\\n",
    "  --peft-model finetuned_models/safelora-alpaca-7b  \\\n",
    "  --prompt_file safety_evaluation/data/demo_examples.csv \\\n",
    "  --prompt_template_style alpaca \\\n",
    "  --output_file safety_evaluation/question_output/demo_examples_safelora-alpaca-7b.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbfd542",
   "metadata": {},
   "source": [
    "Then, launch the GPT-4 Judge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e0e27",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python safety_evaluation/gpt4_eval.py --input_file safety_evaluation/question_output/demo_examples_safelora-alpaca-7b.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614e2915",
   "metadata": {},
   "source": [
    "### Capability evals\n",
    "\n",
    "Generate the model's answers to the 80 MT-Bench questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37655b53",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Install FastChat\n",
    " !git clone https://github.com/lm-sys/FastChat.git && \\\n",
    "pip install -e 'FastChat[model_worker,llm_judge]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3b5830",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python -u utility_evaluation/mt_bench/gen_model_answer.py \\\n",
    "    --model_name TheBloke/Llama-2-7B-Chat-fp16 \\\n",
    "    --peft-model finetuned_models/safelora-alpaca-7b  \\\n",
    "    --model_id safelora-alpaca-7b \\\n",
    "    --prompt_template_style alpaca "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da15ed",
   "metadata": {},
   "source": [
    "Generate GPT-4 judgments for these answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28bb7aa",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python utility_evaluation/mt_bench/gen_judgment.py --model-list safelora-alpaca-7b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f357be",
   "metadata": {},
   "source": [
    "Show summary of the evaluation results (e.g. average score):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef54dff0",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python utility_evaluation/mt_bench/show_result.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
